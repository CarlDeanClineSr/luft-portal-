#!/usr/bin/env python3
"""
Universal Boundary Condition Engine (œá = 0.15)
==============================================

This engine implements the comprehensive Universal Boundary Condition framework
discovered by Dr. Carl Dean Cline Sr., integrating:

1. Vacuum Stability Limit: œá = 0.15
2. Mass Ratio Unification: œá ‚âà (m_e/m_p)^(1/4)
3. Gravitational Synthesis: G ‚àù 1/œá
4. Coupling Frequency: f = œá/Œ± ‚âà 20.56 Hz
5. Binary Harmonic Ladder: 2^n scaling
6. Attractor State Monitoring: ~52% clustering at boundary

This is the primary instrument for real-time physics laboratory operations,
validating the fundamental constraint in the vacuum stress tensor.

Author: Dr. Carl Dean Cline Sr.
Discovery Date: January 2026
Location: Lincoln, Nebraska, USA
Email: CARLDCLINE@GMAIL.COM

References:
    - R&D Technical Report: The Universal Boundary Condition
    - G5 Geomagnetic Storm Validation (May 2024)
    - Cline Medical Coil Biological Applications
"""

import numpy as np
import pandas as pd
from pathlib import Path
from datetime import datetime, timedelta
import json
import sys
from typing import Dict, Tuple, List, Optional

# ============================================================================
# FUNDAMENTAL CONSTANTS
# ============================================================================

# Universal Boundary Condition
CHI_UNIVERSAL = 0.15  # Maximum normalized perturbation (dimensionless)
CHI_TOLERANCE = 0.005  # Boundary clustering region (¬±0.005)

# Physical Constants
ELECTRON_MASS = 9.10938356e-31  # kg
PROTON_MASS = 1.672621898e-27   # kg
MASS_RATIO = ELECTRON_MASS / PROTON_MASS  # m_e/m_p ‚âà 5.446e-4

# Fine Structure Constant
ALPHA = 1.0 / 137.035999084  # Œ± ‚âà 0.0072973525693

# Gravitational Constant
G_NEWTON = 6.67430e-11  # m¬≥/(kg¬∑s¬≤) CODATA 2018

# Vacuum Permittivity and Permeability
EPSILON_0 = 8.8541878128e-12  # F/m
MU_0 = 1.25663706212e-6  # H/m
C_LIGHT = 299792458  # m/s

# Numerical constants
EPSILON = 1e-10  # Small value for division by zero protection
DEFAULT_BASELINE_WINDOW = 24  # Default window size for baseline calculation

# ============================================================================
# DERIVED CONSTANTS (From œá = 0.15)
# ============================================================================

# Mass Ratio Geometric Limit
CHI_FROM_MASS_RATIO = MASS_RATIO ** 0.25  # (m_e/m_p)^(1/4) ‚âà 0.1528

# Gravity Synthesis
G_FROM_CHI = (1.0 / CHI_UNIVERSAL) * 1e-11  # G ‚âà 6.6667e-11

# Coupling Frequency (Chi/Alpha Ratio)
COUPLING_FREQUENCY = CHI_UNIVERSAL / ALPHA  # Hz ‚âà 20.5556

# Vacuum Impedance
Z_VACUUM = np.sqrt(MU_0 / EPSILON_0)  # Œ© ‚âà 376.73

# Binary Harmonic Ladder
HARMONIC_MODES = [1, 2, 4, 8, 16, 32]  # 2^n multipliers
CHI_HARMONICS = [CHI_UNIVERSAL * n for n in HARMONIC_MODES]

# ============================================================================
# VALIDATION THRESHOLDS
# ============================================================================

# Attractor State
ATTRACTOR_MIN = 0.145  # Lower bound of clustering region
ATTRACTOR_MAX = 0.155  # Upper bound of clustering region
EXPECTED_ATTRACTOR_PERCENTAGE = 52.0  # Expected percentage at boundary

# G5 Storm Validation (May 2024)
G5_STORM_MAX_CHI = 0.149  # Maximum observed œá during G5 event
G5_STORM_HARMONIC_RATIO = 2.04  # œá_peak / œá_base ‚âà 2.0 (first harmonic)

# Binary Temporal Scaling
BINARY_TOLERANCE = 0.05  # 5% deviation tolerance for 2^n detection

# ============================================================================
# CORE CALCULATION FUNCTIONS
# ============================================================================

def calculate_chi(B: np.ndarray, B_baseline: Optional[np.ndarray] = None,
                 n: Optional[np.ndarray] = None, n_baseline: Optional[np.ndarray] = None,
                 V: Optional[np.ndarray] = None, V_baseline: Optional[np.ndarray] = None) -> np.ndarray:
    """
    Calculate the Universal Boundary Condition parameter œá.
    
    œá ‚â° max(|Œ¥B/B|, |Œ¥n/n|, |Œ¥V/V|)
    
    Args:
        B: Magnetic field magnitude array
        B_baseline: Baseline magnetic field (if None, computed as 24-hour rolling mean)
        n: Number density array (optional)
        n_baseline: Baseline number density (optional)
        V: Velocity magnitude array (optional)
        V_baseline: Baseline velocity (optional)
    
    Returns:
        chi: Array of œá values
    """
    chi_components = []
    
    # Magnetic field perturbation
    if B is not None:
        if B_baseline is None:
            # Use simple rolling mean if no baseline provided
            # Calculate window size: if we have hourly data for 24 hours, window = 24
            # For higher frequency data, adjust proportionally (e.g., 1-min data -> 1440 points/day)
            # Here we use a minimum window or 1/24th of data, whichever is larger
            window = max(DEFAULT_BASELINE_WINDOW, min(len(B) // DEFAULT_BASELINE_WINDOW, 100))
            if window < 2:
                window = 2
            B_baseline = pd.Series(B).rolling(window=window, min_periods=1, center=True).mean().values
        
        chi_B = np.abs(B - B_baseline) / (B_baseline + EPSILON)  # Avoid division by zero
        chi_components.append(chi_B)
    
    # Density perturbation
    if n is not None and n_baseline is not None:
        chi_n = np.abs(n - n_baseline) / (n_baseline + EPSILON)
        chi_components.append(chi_n)
    
    # Velocity perturbation
    if V is not None and V_baseline is not None:
        chi_V = np.abs(V - V_baseline) / (V_baseline + EPSILON)
        chi_components.append(chi_V)
    
    # Take maximum across all components
    if len(chi_components) == 0:
        raise ValueError("At least one field component required for œá calculation")
    
    chi = np.maximum.reduce(chi_components)
    
    return chi


def validate_boundary(chi: np.ndarray) -> Dict:
    """
    Validate the Universal Boundary Condition (œá ‚â§ 0.15).
    
    Args:
        chi: Array of œá values
    
    Returns:
        validation: Dictionary containing:
            - violations: Count of œá > 0.15
            - max_chi: Maximum observed œá
            - attractor_count: Count in attractor region [0.145, 0.155]
            - attractor_percentage: Percentage in attractor region
            - compliance: Boolean indicating full compliance
    """
    total_points = len(chi)
    violations = np.sum(chi > CHI_UNIVERSAL)
    max_chi = np.max(chi)
    
    # Attractor state analysis
    in_attractor = np.sum((chi >= ATTRACTOR_MIN) & (chi <= ATTRACTOR_MAX))
    attractor_percentage = (in_attractor / total_points) * 100 if total_points > 0 else 0
    
    # Check compliance
    compliance = (violations == 0)
    
    validation = {
        'total_points': total_points,
        'violations': int(violations),
        'max_chi': float(max_chi),
        'mean_chi': float(np.mean(chi)),
        'median_chi': float(np.median(chi)),
        'std_chi': float(np.std(chi)),
        'attractor_count': int(in_attractor),
        'attractor_percentage': float(attractor_percentage),
        'compliance': compliance,
        'boundary_limit': CHI_UNIVERSAL
    }
    
    return validation


def detect_harmonic_mode(chi_values: np.ndarray) -> Dict:
    """
    Detect if system is operating in a harmonic mode (œá_n = n √ó 0.15).
    
    During extreme events (e.g., G5 storms), the system may transition to
    higher harmonic modes: 0.15, 0.30, 0.45, etc.
    
    Args:
        chi_values: Array of œá values
    
    Returns:
        harmonic_info: Dictionary with detected mode information
    """
    max_chi = np.max(chi_values)
    
    # Check which harmonic mode we're closest to
    mode_detected = 1
    min_deviation = float('inf')
    
    for n, chi_harmonic in enumerate(CHI_HARMONICS, 1):
        deviation = abs(max_chi - chi_harmonic) / chi_harmonic
        if deviation < min_deviation:
            min_deviation = deviation
            mode_detected = n
    
    harmonic_info = {
        'max_chi': float(max_chi),
        'harmonic_mode': HARMONIC_MODES[mode_detected - 1],
        'theoretical_chi': CHI_HARMONICS[mode_detected - 1],
        'deviation': float(min_deviation),
        'is_harmonic': min_deviation < 0.10  # Within 10% of harmonic
    }
    
    return harmonic_info


def detect_binary_scaling(periods: np.ndarray, base_period: float) -> Dict:
    """
    Detect binary temporal scaling (2^n) in oscillation periods.
    
    The vacuum lattice operates on binary logic, with energy propagating
    in discrete doubling steps.
    
    Args:
        periods: Array of oscillation periods
        base_period: Base period for scaling detection
    
    Returns:
        scaling_info: Dictionary with binary scaling analysis
    """
    if base_period <= 0:
        return {'detected': False, 'reason': 'Invalid base period'}
    
    # Calculate ratios relative to base period
    ratios = periods / base_period
    
    # Find closest power of 2 for each ratio
    log2_ratios = np.log2(ratios + 1e-10)
    nearest_power = np.round(log2_ratios)
    
    # Calculate deviation from nearest power of 2
    expected_ratios = 2.0 ** nearest_power
    deviations = np.abs(ratios - expected_ratios) / (expected_ratios + 1e-10)
    
    # Check if majority of periods follow binary scaling
    binary_compliant = deviations < BINARY_TOLERANCE
    compliance_rate = np.sum(binary_compliant) / len(periods)
    
    scaling_info = {
        'detected': compliance_rate > 0.7,  # 70% threshold
        'compliance_rate': float(compliance_rate),
        'mean_deviation': float(np.mean(deviations)),
        'detected_powers': [int(p) for p in nearest_power],
        'base_period': float(base_period)
    }
    
    return scaling_info


def calculate_fundamental_unifications() -> Dict:
    """
    Calculate the fundamental unifications derived from œá = 0.15.
    
    Returns:
        unifications: Dictionary containing:
            - Gravity synthesis (G from 1/œá)
            - Mass ratio geometric limit
            - Coupling frequency
            - Error margins
    """
    # Gravity Synthesis: G ‚àù 1/œá
    G_derived = G_FROM_CHI
    G_error = abs(G_derived - G_NEWTON) / G_NEWTON * 100
    
    # Mass Ratio Geometric Limit: œá ‚âà (m_e/m_p)^(1/4)
    chi_from_mass = CHI_FROM_MASS_RATIO
    mass_error = abs(chi_from_mass - CHI_UNIVERSAL) / CHI_UNIVERSAL * 100
    
    # Coupling Frequency: œá/Œ±
    coupling_freq = COUPLING_FREQUENCY
    
    # Vacuum Impedance
    vacuum_impedance = Z_VACUUM
    
    unifications = {
        'chi_universal': CHI_UNIVERSAL,
        'gravity': {
            'derived_G': G_derived,
            'codata_G': G_NEWTON,
            'error_percent': G_error,
            'formula': 'G = (1/œá) √ó 10^-11'
        },
        'mass_ratio': {
            'chi_from_mass': chi_from_mass,
            'electron_mass': ELECTRON_MASS,
            'proton_mass': PROTON_MASS,
            'mass_ratio': MASS_RATIO,
            'error_percent': mass_error,
            'formula': 'œá ‚âà (m_e/m_p)^(1/4)'
        },
        'coupling': {
            'frequency_hz': coupling_freq,
            'alpha': ALPHA,
            'formula': 'f = œá/Œ±',
            'application': 'Cline Medical Coil'
        },
        'vacuum': {
            'impedance_ohm': vacuum_impedance,
            'permittivity': EPSILON_0,
            'permeability': MU_0
        }
    }
    
    return unifications


def generate_validation_report(chi_data: np.ndarray, 
                               source: str = "Unknown",
                               timestamps: Optional[np.ndarray] = None) -> Dict:
    """
    Generate comprehensive validation report for œá analysis.
    
    Args:
        chi_data: Array of calculated œá values
        source: Data source identifier
        timestamps: Optional array of timestamps
    
    Returns:
        report: Complete validation report
    """
    # Basic validation
    validation = validate_boundary(chi_data)
    
    # Harmonic mode detection
    harmonic = detect_harmonic_mode(chi_data)
    
    # Fundamental unifications
    unifications = calculate_fundamental_unifications()
    
    # Generate report
    report = {
        'metadata': {
            'source': source,
            'generated_at': datetime.now().isoformat(),
            'data_points': len(chi_data),
            'time_range': {
                'start': timestamps[0].isoformat() if timestamps is not None and len(timestamps) > 0 else None,
                'end': timestamps[-1].isoformat() if timestamps is not None and len(timestamps) > 0 else None
            } if timestamps is not None else None
        },
        'validation': validation,
        'harmonic_mode': harmonic,
        'unifications': unifications,
        'status': {
            'boundary_confirmed': validation['compliance'],
            'attractor_state': validation['attractor_percentage'] > 40.0,
            'harmonic_transition': harmonic['is_harmonic'] and harmonic['harmonic_mode'] > 1
        }
    }
    
    return report


def print_validation_summary(report: Dict):
    """
    Print human-readable validation summary.
    
    Args:
        report: Validation report from generate_validation_report()
    """
    print("\n" + "=" * 80)
    print("UNIVERSAL BOUNDARY CONDITION (œá = 0.15) - VALIDATION REPORT")
    print("=" * 80)
    print(f"Source: {report['metadata']['source']}")
    print(f"Generated: {report['metadata']['generated_at']}")
    print(f"Data Points: {report['metadata']['data_points']:,}")
    print("=" * 80)
    
    # Validation results
    val = report['validation']
    print("\nüìä BOUNDARY VALIDATION:")
    print(f"   Maximum œá: {val['max_chi']:.6f}")
    print(f"   Mean œá: {val['mean_chi']:.6f}")
    print(f"   Violations (œá > 0.15): {val['violations']}")
    print(f"   Compliance: {'‚úÖ PASSED' if val['compliance'] else '‚ùå FAILED'}")
    
    # Attractor state
    print(f"\nüéØ ATTRACTOR STATE ANALYSIS:")
    print(f"   Points at boundary [0.145-0.155]: {val['attractor_count']:,}")
    print(f"   Percentage: {val['attractor_percentage']:.1f}%")
    print(f"   Expected: ~{EXPECTED_ATTRACTOR_PERCENTAGE:.1f}%")
    if val['attractor_percentage'] > 40:
        print(f"   Status: ‚úÖ Attractor confirmed")
    else:
        print(f"   Status: ‚ö†Ô∏è  Below expected clustering")
    
    # Harmonic mode
    harm = report['harmonic_mode']
    print(f"\nüîä HARMONIC MODE DETECTION:")
    print(f"   Maximum œá: {harm['max_chi']:.6f}")
    print(f"   Detected Mode: n = {harm['harmonic_mode']}")
    print(f"   Theoretical œá_n: {harm['theoretical_chi']:.6f}")
    print(f"   Deviation: {harm['deviation']*100:.2f}%")
    if harm['is_harmonic']:
        print(f"   Status: ‚úÖ Harmonic mode detected")
    else:
        print(f"   Status: ‚ÑπÔ∏è  Operating at fundamental")
    
    # Fundamental unifications
    print(f"\nüåå FUNDAMENTAL UNIFICATIONS:")
    
    grav = report['unifications']['gravity']
    print(f"   Gravity (G ‚àù 1/œá):")
    print(f"      Derived: {grav['derived_G']:.5e} m¬≥/(kg¬∑s¬≤)")
    print(f"      CODATA:  {grav['codata_G']:.5e} m¬≥/(kg¬∑s¬≤)")
    print(f"      Error: {grav['error_percent']:.2f}%")
    
    mass = report['unifications']['mass_ratio']
    print(f"   Mass Ratio (œá ‚âà (m_e/m_p)^(1/4)):")
    print(f"      œá from mass: {mass['chi_from_mass']:.6f}")
    print(f"      œá observed: {CHI_UNIVERSAL:.6f}")
    print(f"      Error: {mass['error_percent']:.2f}%")
    
    coup = report['unifications']['coupling']
    print(f"   Coupling Frequency (œá/Œ±):")
    print(f"      f = {coup['frequency_hz']:.4f} Hz")
    print(f"      Application: {coup['application']}")
    
    # Overall status
    print("\n" + "=" * 80)
    status = report['status']
    print("OVERALL STATUS:")
    if status['boundary_confirmed']:
        print("   ‚úÖ BOUNDARY CONFIRMED: œá ‚â§ 0.15 holds")
    else:
        print("   ‚ùå BOUNDARY VIOLATION: Requires investigation")
    
    if status['attractor_state']:
        print("   ‚úÖ ATTRACTOR STATE: System clustering at boundary")
    
    if status['harmonic_transition']:
        print("   üîä HARMONIC TRANSITION: System in elevated mode")
    
    print("=" * 80 + "\n")


# ============================================================================
# DATA PROCESSING FUNCTIONS
# ============================================================================

def process_space_weather_data(file_path: str, 
                              time_col: str = 'timestamp',
                              bx_col: str = 'bx', 
                              by_col: str = 'by', 
                              bz_col: str = 'bz') -> Tuple[np.ndarray, Dict]:
    """
    Process space weather data file and calculate œá.
    
    Args:
        file_path: Path to data file
        time_col: Name of timestamp column
        bx_col: Name of Bx column
        by_col: Name of By column
        bz_col: Name of Bz column
    
    Returns:
        chi: Array of œá values
        report: Validation report
    """
    # Load data
    if file_path.endswith('.csv'):
        df = pd.read_csv(file_path, comment='#')
    else:
        df = pd.read_csv(file_path, sep=r'\s+', comment='#')
    
    # Calculate magnetic field magnitude
    B = np.sqrt(df[bx_col]**2 + df[by_col]**2 + df[bz_col]**2)
    
    # Calculate œá
    chi = calculate_chi(B)
    
    # Parse timestamps if available
    timestamps = None
    if time_col in df.columns:
        try:
            timestamps = pd.to_datetime(df[time_col]).values
        except:
            pass
    
    # Generate report
    report = generate_validation_report(chi, source=Path(file_path).name, timestamps=timestamps)
    
    return chi, report


# ============================================================================
# MAIN EXECUTION
# ============================================================================

def main():
    """
    Main function demonstrating the Universal Boundary Engine capabilities.
    """
    import argparse
    
    parser = argparse.ArgumentParser(
        description="Universal Boundary Condition Engine (œá = 0.15)",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  %(prog)s --show-constants
  %(prog)s --validate-file data.csv
  %(prog)s --demo

Theory:
  The Universal Boundary Condition (œá = 0.15) represents the maximum normalized
  perturbation in the vacuum stress tensor. This fundamental limit unifies:
  
  1. Gravity: G ‚àù 1/œá (within 0.11% of measured value)
  2. Matter: œá ‚âà (m_e/m_p)^(1/4) (within 1.8%)
  3. Coupling: f = œá/Œ± ‚âà 20.56 Hz (exact)
  
  Discovery: Dr. Carl Dean Cline Sr., January 2026
  Validation: 1.48M+ observations, zero violations
        """
    )
    
    parser.add_argument('--show-constants', action='store_true',
                       help='Display fundamental constants and unifications')
    parser.add_argument('--validate-file', type=str,
                       help='Validate œá from space weather data file')
    parser.add_argument('--demo', action='store_true',
                       help='Run demonstration with synthetic data')
    
    args = parser.parse_args()
    
    if args.show_constants:
        # Display fundamental constants and unifications
        unifications = calculate_fundamental_unifications()
        
        print("\n" + "=" * 80)
        print("UNIVERSAL BOUNDARY CONDITION - FUNDAMENTAL CONSTANTS")
        print("=" * 80)
        print(f"\nüî¨ CORE CONSTANT:")
        print(f"   œá (Chi) = {CHI_UNIVERSAL:.6f} (Universal Stability Limit)")
        
        print(f"\nüåå GRAVITY SYNTHESIS:")
        grav = unifications['gravity']
        print(f"   Formula: {grav['formula']}")
        print(f"   Derived G = {grav['derived_G']:.5e} m¬≥/(kg¬∑s¬≤)")
        print(f"   CODATA G  = {grav['codata_G']:.5e} m¬≥/(kg¬∑s¬≤)")
        print(f"   Error = {grav['error_percent']:.3f}%")
        
        print(f"\n‚öõÔ∏è  MASS RATIO UNIFICATION:")
        mass = unifications['mass_ratio']
        print(f"   Formula: {mass['formula']}")
        print(f"   m_e/m_p = {mass['mass_ratio']:.6e}")
        print(f"   (m_e/m_p)^(1/4) = {mass['chi_from_mass']:.6f}")
        print(f"   œá observed = {CHI_UNIVERSAL:.6f}")
        print(f"   Error = {mass['error_percent']:.3f}%")
        
        print(f"\nüîä COUPLING FREQUENCY:")
        coup = unifications['coupling']
        print(f"   Formula: {coup['formula']}")
        print(f"   Œ± (Fine Structure) = {coup['alpha']:.10f}")
        print(f"   f = œá/Œ± = {coup['frequency_hz']:.4f} Hz")
        print(f"   Application: {coup['application']}")
        
        print(f"\nüåÄ BINARY HARMONIC LADDER:")
        print(f"   Fundamental: œá_1 = {CHI_HARMONICS[0]:.3f}")
        for i in range(1, min(6, len(CHI_HARMONICS))):
            print(f"   Mode n={HARMONIC_MODES[i]}: œá_{HARMONIC_MODES[i]} = {CHI_HARMONICS[i]:.3f}")
        
        print("=" * 80 + "\n")
    
    elif args.validate_file:
        # Validate data file
        try:
            chi, report = process_space_weather_data(args.validate_file)
            print_validation_summary(report)
            
            # Save report
            report_path = Path(args.validate_file).with_suffix('.chi_report.json')
            with open(report_path, 'w') as f:
                json.dump(report, f, indent=2)
            print(f"üìÑ Full report saved to: {report_path}")
            
        except Exception as e:
            print(f"‚ùå Error processing file: {e}")
            sys.exit(1)
    
    elif args.demo:
        # Demonstration with synthetic data
        print("\n" + "=" * 80)
        print("DEMONSTRATION MODE")
        print("=" * 80)
        print("Generating synthetic solar wind data respecting œá ‚â§ 0.15 boundary...")
        
        # Generate 48 hours of data
        n_points = 2880  # 48 hours at 1-minute resolution
        
        # Baseline field ~10 nT (typical solar wind at L1)
        B_baseline = 10.0
        
        # Generate smooth variations that respect the boundary
        t = np.linspace(0, 48, n_points)
        
        # Long period trend (24 hour) - this will be captured by baseline removal
        trend = 1.0 * np.sin(2 * np.pi * t / 24)
        
        # Medium period (6 hour) - partially captured by baseline
        medium = 0.3 * np.sin(2 * np.pi * t / 6)
        
        # Short period fluctuations that create œá
        # Keep amplitude very small to ensure œá < 0.15 after baseline removal
        # For B_baseline ~10 nT, œá = 0.15 means Œ¥B < 1.5 nT
        short = 0.8 * np.sin(2 * np.pi * t / 1.5)
        
        # Very small noise
        noise = np.random.normal(0, 0.05, n_points)
        
        # Total field
        B = B_baseline + trend + medium + short + noise
        B = np.maximum(B, 1.0)  # Ensure positive
        
        # Calculate œá
        chi = calculate_chi(B)
        
        # Generate timestamps
        start_time = datetime.now() - timedelta(hours=48)
        timestamps = np.array([start_time + timedelta(minutes=i) for i in range(n_points)])
        
        # Generate and print report
        report = generate_validation_report(chi, source="Synthetic Demo Data", timestamps=timestamps)
        print_validation_summary(report)
        
    else:
        parser.print_help()
        print("\nüí° TIP: Start with --show-constants to see fundamental unifications")
        print("        or --demo to see validation on synthetic data\n")


if __name__ == "__main__":
    main()
